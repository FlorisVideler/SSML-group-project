{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b60cacd",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7063b125-9e72-4d12-a3ef-987ed27ee462",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43e2c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import geopandas as gpd\n",
    "from rasterio.features import rasterize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35887d9-9454-44f2-82b4-bb0ba7dc4b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, MaxPooling2D, Dropout, Conv2DTranspose, concatenate\n",
    "from tensorflow.keras import layers, models, optimizers, losses, metrics\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import register_keras_serializable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4883b69-579a-4d6a-abbd-035b2ba78029",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1f2ad9-7810-4a91-b107-b46fc474650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_rasterize_image(tif_path, shape_file_path):\n",
    "    with rasterio.open(tif_path) as src:\n",
    "        image = src.read([1, 2, 3])  # Reading the first three bands (assuming RGB)\n",
    "        transform = src.transform\n",
    "\n",
    "    # Read the shapefile\n",
    "    shapes = gpd.read_file(shape_file_path)\n",
    "\n",
    "    # Rasterize the shapefile to create a mask\n",
    "    mask = rasterize(\n",
    "        [(shape, 1) for shape in shapes.geometry],\n",
    "        out_shape=image[0].shape,\n",
    "        transform=transform,\n",
    "        fill=0,\n",
    "        all_touched=True,\n",
    "        dtype='uint8'\n",
    "    )\n",
    "    \n",
    "\n",
    "    # Normalize the image\n",
    "    image = image / 255.0\n",
    "    return image.transpose((1, 2, 0)), mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c330de2-6526-43e2-a67f-181d2d55c632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_into_patches(image, mask, patch_size):\n",
    "    \"\"\"\n",
    "    Divides an image and its mask into smaller patches.\n",
    "\n",
    "    Parameters:\n",
    "    - image: The image to be divided (numpy array).\n",
    "    - mask: The corresponding mask for the image (numpy array).\n",
    "    - patch_size: The size of each patch (tuple of two integers).\n",
    "\n",
    "    Returns:\n",
    "    - image_patches: A list of image patches.\n",
    "    - mask_patches: A list of mask patches.\n",
    "    \"\"\"\n",
    "    # Ensure the input dimensions are compatible\n",
    "    assert image.shape[0:2] == mask.shape[0:2], \"Image and mask must have the same dimensions\"\n",
    "    \n",
    "    # Calculate the number of patches along each dimension\n",
    "    patches_along_height = image.shape[0] // patch_size[0]\n",
    "    patches_along_width = image.shape[1] // patch_size[1]\n",
    "\n",
    "    image_patches = []\n",
    "    mask_patches = []\n",
    "\n",
    "    for i in range(patches_along_height):\n",
    "        for j in range(patches_along_width):\n",
    "            # Calculate patch coordinates\n",
    "            start_row = i * patch_size[0]\n",
    "            end_row = start_row + patch_size[0]\n",
    "            start_col = j * patch_size[1]\n",
    "            end_col = start_col + patch_size[1]\n",
    "\n",
    "            # Extract patches\n",
    "            image_patch = image[start_row:end_row, start_col:end_col]\n",
    "            mask_patch = mask[start_row:end_row, start_col:end_col]\n",
    "\n",
    "            image_patches.append(image_patch)\n",
    "            mask_patches.append(mask_patch)\n",
    "\n",
    "    return np.array(image_patches), np.array(mask_patches)\n",
    "\n",
    "def reshape_into_patched(image, mask, patch_size):\n",
    "    patch_size = list(patch_size)\n",
    "    mosaic_size = tuple(patch_size.insert(0, -1))\n",
    "    return image.reshape(mosaic_size), mask_patches.reshape(mosaic_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5692a950-35c5-4bad-bbfc-63795c447245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(file_names):\n",
    "    folds = {}\n",
    "    for i, file_name in enumerate(file_names):\n",
    "        mask_path = f\"masks/{file_name}.gpkg\"\n",
    "        tif_path = f\"nl_8cm/{file_name}.tif\"\n",
    "        image, mask = read_and_rasterize_image(tif_path, mask_path)\n",
    "        image, mask = divide_into_patches(image=image, mask=mask, patch_size=(512, 512))\n",
    "        # image, mask = reshape_into_patched(image=image, mask=mask, patch_size=(500, 500))\n",
    "        folds[i] = {\"images\": image, \"masks\": mask}\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156ee80d-ddd8-40c6-98bf-15b401b9bb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images_masks(folds, n_images = 10):\n",
    "    fold = 0\n",
    "    \n",
    "    num_images = len(folds[fold]['images'])\n",
    "    indices = np.random.choice(range(num_images), size=n_images, replace=False)\n",
    "    \n",
    "    # Set up the matplotlib figure and axes\n",
    "    fig, axs = plt.subplots(10, 2, figsize=(10, 40))  # Adjust figsize as needed\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        image = folds[fold][\"images\"][idx] # Load the image\n",
    "        mask = folds[fold][\"masks\"][idx]  # Load the corresponding mask\n",
    "    \n",
    "        axs[i, 0].imshow(image, cmap='gray')\n",
    "        axs[i, 0].axis('off')  # Remove axis ticks and labels\n",
    "        axs[i, 0].set_title(f\"Image {idx}\")\n",
    "    \n",
    "        axs[i, 1].imshow(mask, cmap='gray')\n",
    "        axs[i, 1].axis('off')\n",
    "        axs[i, 1].set_title(f\"Mask {idx}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc41a7d-f2bf-4b26-aa1d-25efaea20a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sets_from_folds(folds):\n",
    "    train_folds = [0, 1, 2, 3]\n",
    "    test_fold = 4\n",
    "    \n",
    "    X_train = np.concatenate([folds[i]['images'] for i in train_folds], axis=0)\n",
    "    y_train = np.concatenate([folds[i]['masks'] for i in train_folds], axis=0)\n",
    "    X_test, y_test = folds[test_fold]['images'], folds[test_fold]['masks']\n",
    "    return (X_train, y_train), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef95fb0b-e56e-499f-ab58-572fcb6ddc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=16\n",
    "train_dataset_save_path = 'train_dataset'\n",
    "test_dataset_save_path = 'test_dataset'\n",
    "\n",
    "file_names = [\"2022_131000_456000_RGB_hrl\", \"2022_133000_456000_RGB_hrl\", \"2022_136000_457000_RGB_hrl\", \"2022_129000_458000_RGB_hrl\", \"2022_132000_455000_RGB_hrl\"]\n",
    "patch_size = (512, 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0ef632-1ea6-4c0e-beb2-4a755f5500a8",
   "metadata": {},
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b77c680-8060-426c-a167-7c98616db325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment for preprocessing\n",
    "# folds = pre_process(file_names)\n",
    "# print(\"Loaded all images & mosaiced them.\")\n",
    "\n",
    "# # show_images_masks(folds)\n",
    "\n",
    "# (X_train, y_train), (X_test, y_test) = create_sets_from_folds(folds)\n",
    "# print(\"Created folds and put them together as a train & test sets.\")\n",
    "# print(\n",
    "#     X_train.shape,\n",
    "#     y_train.shape,\n",
    "#     X_test.shape\n",
    "# )\n",
    "\n",
    "# # Convert data to tf.data.Dataset and cast to float32\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices((X_train.astype(np.float32), y_train.astype(np.uint8)))\n",
    "# test_dataset = tf.data.Dataset.from_tensor_slices((X_test.astype(np.float32), y_test.astype(np.uint8)))\n",
    "# print(\"Converted sets to tf.Datasets and casted to float32.\")\n",
    "\n",
    "# # Shuffle, batch, and prefetch the training dataset\n",
    "# train_dataset = train_dataset.shuffle(buffer_size=len(X_train)).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# # Batch and prefetch the test dataset\n",
    "# test_dataset = test_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "# print(\"Buffered & batched sets.\")\n",
    "\n",
    "# # Save training dataset\n",
    "# train_dataset_save_path = 'train_dataset'\n",
    "# tf.data.Dataset.save(train_dataset, train_dataset_save_path) # options=compression_opts\n",
    "# print(\"Saved Train set.\")\n",
    "\n",
    "# # Save test dataset\n",
    "# test_dataset_save_path = 'test_dataset'\n",
    "# tf.data.Dataset.save(test_dataset, test_dataset_save_path) # options=compression_opts\n",
    "# print(\"Saved Test set.\")\n",
    "\n",
    "\n",
    "# del folds\n",
    "# del X_train\n",
    "# del y_train\n",
    "# del X_test\n",
    "# del y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7d141d-eb0c-4343-a891-0ef01ce296e1",
   "metadata": {},
   "source": [
    "## Loading the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0891e188-b78d-4948-b37b-f7c695b5cb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training dataset\n",
    "train_dataset = tf.data.Dataset.load(train_dataset_save_path, \n",
    "                                           element_spec=(tf.TensorSpec(shape=(patch_size[0], patch_size[1], 3), dtype=tf.float32),\n",
    "                                                         tf.TensorSpec(shape=(patch_size[0], patch_size[1]), dtype=tf.uint8)))\n",
    "\n",
    "# Load test dataset\n",
    "test_dataset = tf.data.Dataset.load(test_dataset_save_path, \n",
    "                                          element_spec=(tf.TensorSpec(shape=(patch_size[0], patch_size[1], 3), dtype=tf.float32),\n",
    "                                                        tf.TensorSpec(shape=(patch_size[0], patch_size[1]), dtype=tf.uint8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64191818-085c-4e64-afc4-769d8590118c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.batch(batch_size)\n",
    "test_dataset = test_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6eacd2-1f15-4ebc-82fd-c776c174a6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.element_spec, test_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12c4f5e-0512-4369-81e7-ce765cb94738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(y_true, y_pred):\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection\n",
    "    iou_score = intersection / (union + tf.keras.backend.epsilon())  # Add epsilon to avoid division by zero\n",
    "    return iou_score\n",
    "\n",
    "def iou_loss(y_true, y_pred):\n",
    "    return 1.0 - iou(y_true, y_pred)  # Minimize 1 - IoU\n",
    "\n",
    "def focal_loss(y_true, y_pred, alpha=0.25, gamma=2.0):\n",
    "    epsilon = 1e-7\n",
    "    y_pred = tf.clip_by_value(y_pred, epsilon, 1.0 - epsilon)\n",
    "    pt = tf.where(tf.equal(y_true, 1), y_pred, 1 - y_pred)\n",
    "    focal_loss = -alpha * (1.0 - pt) ** gamma * tf.math.log(pt)\n",
    "    return tf.reduce_mean(focal_loss)\n",
    "\n",
    "def weighted_binary_crossentropy(y_true, y_pred, weight_background=1, weight_subjects=100):\n",
    "    epsilon = 1e-7\n",
    "    y_pred = tf.clip_by_value(y_pred, epsilon, 1.0 - epsilon)\n",
    "    loss = -weight_background * y_true * tf.math.log(y_pred) - weight_subjects * (1.0 - y_true) * tf.math.log(1.0 - y_pred)\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89d2e13-d7fb-4642-9b4a-8dffd6759f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def iou(y_true, y_pred):\n",
    "#     intersection = tf.reduce_sum(y_true * y_pred)\n",
    "#     union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection\n",
    "#     iou_score = intersection / (union + tf.keras.backend.epsilon())  # Add epsilon to avoid division by zero\n",
    "#     return iou_score\n",
    "    \n",
    "# def iou_loss(y_true, y_pred):\n",
    "#     return 1.0 - iou(y_true, y_pred)  # Minimize 1 - IoU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594a8766-ee4a-41b2-a503-32f51f15b01f",
   "metadata": {},
   "source": [
    "# Building models\n",
    "\n",
    "## U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8895fed2-c7bc-408b-bd4c-78616d059c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(inputs, num_filters, drop_out=0):\n",
    "    x = layers.Conv2D(num_filters, 3, padding=\"same\")(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = tf.keras.activations.relu(x)\n",
    "    if drop_out > 0:\n",
    "        x = layers.Dropout(drop_out)(x)\n",
    "    \n",
    "    x = layers.Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = tf.keras.activations.relu(x)\n",
    "    if drop_out > 0:\n",
    "        x = layers.Dropout(drop_out)(x)\n",
    "    return x\n",
    "\n",
    "def downsample_block(inputs, num_filters):\n",
    "    x = conv_block(inputs, num_filters)\n",
    "    p = layers.MaxPooling2D((2, 2))(x)\n",
    "    return x, p\n",
    "\n",
    "def upsample_block(inputs, skip_features, num_filters):\n",
    "    x = layers.Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(inputs)\n",
    "    x = layers.Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "def build_unet(input_shape, drop_out):\n",
    "    inputs = layers.Input(input_shape)\n",
    "\n",
    "    s1, p1 = downsample_block(inputs, 64) # 512 -> 256\n",
    "    s2, p2 = downsample_block(p1, 128) # 256 -> 128\n",
    "    s3, p3 = downsample_block(p2, 256) # 128 -> 64\n",
    "\n",
    "    b = conv_block(p3, 512, drop_out=drop_out)\n",
    "\n",
    "    d1 = upsample_block(b, s3, 256) # 64 -> 128\n",
    "    d2 = upsample_block(d1, s2, 128) # 128 -> 256\n",
    "    d3 = upsample_block(d2, s1, 64) # 256 -> 512\n",
    "\n",
    "    outputs = layers.Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(d3)\n",
    "\n",
    "    model = models.Model(inputs, outputs, name=\"U-Net\")\n",
    "    return model\n",
    "\n",
    "# drop_out = 0.5\n",
    "# model = build_unet(input_shape=(patch_size[0], patch_size[1], 3), drop_out=drop_out)\n",
    "# model_name = f\"{model.name}_d{drop_out}_IOU_test.keras\"\n",
    "# model_name\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53177ba1-6d85-438b-b509-ffdb3f9816ba",
   "metadata": {},
   "source": [
    "## DeeplabV3+\n",
    "Deeplab model with partial resnet backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932d5415-b818-4e5f-8c11-187e2ae66780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_block(\n",
    "    block_input,\n",
    "    num_filters=256,\n",
    "    kernel_size=3,\n",
    "    dilation_rate=1,\n",
    "    use_bias=False,\n",
    "):\n",
    "    x = layers.Conv2D(\n",
    "        num_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        dilation_rate=dilation_rate,\n",
    "        padding=\"same\",\n",
    "        use_bias=use_bias,\n",
    "        kernel_initializer=tf.keras.initializers.HeNormal(),\n",
    "    )(block_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    return tf.keras.ops.nn.relu(x)\n",
    "\n",
    "\n",
    "def DilatedSpatialPyramidPooling(dspp_input):\n",
    "    dims = dspp_input.shape\n",
    "    x = layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)\n",
    "    x = convolution_block(x, kernel_size=1, use_bias=True)\n",
    "    out_pool = layers.UpSampling2D(\n",
    "        size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]),\n",
    "        interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "\n",
    "    out_1 = convolution_block(dspp_input, kernel_size=1, dilation_rate=1)\n",
    "    out_6 = convolution_block(dspp_input, kernel_size=3, dilation_rate=6)\n",
    "    out_12 = convolution_block(dspp_input, kernel_size=3, dilation_rate=12)\n",
    "    out_18 = convolution_block(dspp_input, kernel_size=3, dilation_rate=18)\n",
    "\n",
    "    x = layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])\n",
    "    output = convolution_block(x, kernel_size=1)\n",
    "    return output\n",
    "\n",
    "def DeeplabV3Plus(image_size, num_classes):\n",
    "\n",
    "    model_input = layers.Input(shape=(image_size, image_size, 3))\n",
    "    preprocessed = tf.keras.applications.resnet50.preprocess_input(model_input)\n",
    "    resnet50 = tf.keras.applications.ResNet50(\n",
    "        weights=\"imagenet\", include_top=False, input_tensor=preprocessed\n",
    "    )\n",
    "    x = resnet50.get_layer(\"conv4_block6_2_relu\").output\n",
    "    x = DilatedSpatialPyramidPooling(x)\n",
    "\n",
    "    input_a = layers.UpSampling2D(\n",
    "        size=(image_size // 4 // x.shape[1], image_size // 4 // x.shape[2]),\n",
    "        interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "    input_b = resnet50.get_layer(\"conv2_block3_2_relu\").output\n",
    "    input_b = convolution_block(input_b, num_filters=48, kernel_size=1)\n",
    "\n",
    "    x = layers.Concatenate(axis=-1)([input_a, input_b])\n",
    "    x = convolution_block(x)\n",
    "    x = convolution_block(x)\n",
    "    x = layers.UpSampling2D(\n",
    "        size=(image_size // x.shape[1], image_size // x.shape[2]),\n",
    "        interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "    model_output = layers.Conv2D(num_classes, kernel_size=(1, 1), padding=\"same\", activation=\"sigmoid\")(x)\n",
    "    return models.Model(inputs=model_input, outputs=model_output, name=\"DeepLabV3p\")\n",
    "\n",
    "\n",
    "model = DeeplabV3Plus(image_size=patch_size[0], num_classes=1)\n",
    "model_name = f\"{model.name}_IOU_test.keras\"\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a899fc1c-4bb9-4519-aaad-d06ce2cb2f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear all previously registered custom objects\n",
    "tf.keras.utils.get_custom_objects().clear()\n",
    "\n",
    "\n",
    "@register_keras_serializable(package=\"MyLayers\")\n",
    "class ConvolutionBlock(layers.Layer):\n",
    "    def __init__(self, num_filters=256, kernel_size=3, dilation_rate=1, use_bias=False, **kwargs):\n",
    "        super(ConvolutionBlock, self).__init__(**kwargs)\n",
    "        self.num_filters = num_filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.dilation_rate = dilation_rate\n",
    "        self.use_bias = use_bias\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.conv = layers.Conv2D(\n",
    "            self.num_filters,\n",
    "            kernel_size=self.kernel_size,\n",
    "            dilation_rate=self.dilation_rate,\n",
    "            padding=\"same\",\n",
    "            use_bias=self.use_bias,\n",
    "            kernel_initializer=tf.keras.initializers.HeNormal(),\n",
    "        )\n",
    "        self.batch_norm = layers.BatchNormalization()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv(inputs)\n",
    "        x = self.batch_norm(x)\n",
    "        return tf.nn.relu(x)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(ConvolutionBlock, self).get_config()\n",
    "        config.update({\n",
    "            'num_filters': self.num_filters,\n",
    "            'kernel_size': self.kernel_size,\n",
    "            'dilation_rate': self.dilation_rate,\n",
    "            'use_bias': self.use_bias\n",
    "        })\n",
    "        return config\n",
    "\n",
    "\n",
    "@register_keras_serializable(package=\"MyLayers\")\n",
    "class DilatedSpatialPyramidPooling(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(DilatedSpatialPyramidPooling, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.avg_pool = layers.AveragePooling2D(pool_size=(input_shape[1], input_shape[2]))\n",
    "        self.conv_block_pool = ConvolutionBlock(kernel_size=1, use_bias=True)\n",
    "        self.out_1 = ConvolutionBlock(kernel_size=1, dilation_rate=1)\n",
    "        self.out_6 = ConvolutionBlock(kernel_size=3, dilation_rate=6)\n",
    "        self.out_12 = ConvolutionBlock(kernel_size=3, dilation_rate=12)\n",
    "        self.out_18 = ConvolutionBlock(kernel_size=3, dilation_rate=18)\n",
    "        self.out = ConvolutionBlock(kernel_size=1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        dims = inputs.shape\n",
    "        x = self.avg_pool(inputs)\n",
    "        x = self.conv_block_pool(x)\n",
    "        out_pool = layers.UpSampling2D(size=(dims[1] // x.shape[1], dims[2] // x.shape[2]), interpolation=\"bilinear\")(x)\n",
    "\n",
    "        out_1 = self.out_1(inputs)\n",
    "        out_6 = self.out_6(inputs)\n",
    "        out_12 = self.out_12(inputs)\n",
    "        out_18 = self.out_18(inputs)\n",
    "\n",
    "        x = layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])\n",
    "        output = self.out(x)\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        return super(DilatedSpatialPyramidPooling, self).get_config()\n",
    "\n",
    "\n",
    "\n",
    "@register_keras_serializable(package=\"MyLayers\")\n",
    "class DeepLabV3Plus(models.Model):\n",
    "    def __init__(self, image_size, num_classes, **kwargs):\n",
    "        super(DeepLabV3Plus, self).__init__(**kwargs)\n",
    "        self.image_size = image_size\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        model_input = layers.Input(shape=(self.image_size, self.image_size, 3))\n",
    "        preprocessed = tf.keras.applications.resnet50.preprocess_input(model_input)\n",
    "        resnet50 = tf.keras.applications.ResNet50(\n",
    "            weights=\"imagenet\", include_top=False, input_tensor=preprocessed\n",
    "        )\n",
    "        x = resnet50.get_layer(\"conv4_block6_2_relu\").output\n",
    "        self.dilated_spp = DilatedSpatialPyramidPooling()(x)\n",
    "\n",
    "        input_a = layers.UpSampling2D(size=(self.image_size // 4 // self.dilated_spp.shape[1],\n",
    "                                              self.image_size // 4 // self.dilated_spp.shape[2]),\n",
    "                                      interpolation=\"bilinear\")(self.dilated_spp)\n",
    "        input_b = resnet50.get_layer(\"conv2_block3_2_relu\").output\n",
    "        input_b = ConvolutionBlock(num_filters=48, kernel_size=1)(input_b)\n",
    "\n",
    "        x = layers.Concatenate(axis=-1)([input_a, input_b])\n",
    "        x = ConvolutionBlock()(x)\n",
    "        x = ConvolutionBlock()(x)\n",
    "        x = layers.UpSampling2D(size=(self.image_size // x.shape[1], self.image_size // x.shape[2]),\n",
    "                                interpolation=\"bilinear\")(x)\n",
    "        \n",
    "        # You need to connect the last layer 'x' to the output layer\n",
    "        output = layers.Conv2D(self.num_classes, kernel_size=(1, 1), padding=\"same\", activation=\"sigmoid\")(x)\n",
    "        \n",
    "        # Define model\n",
    "        self.model = models.Model(inputs=model_input, outputs=output)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.model(inputs)\n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(DeepLabV3Plus, self).get_config()\n",
    "        config.update({\n",
    "            'image_size': self.image_size,\n",
    "            'num_classes': self.num_classes\n",
    "        })\n",
    "        return config\n",
    "\n",
    "# Function to build DeepLabV3Plus model\n",
    "def build_DeepLabV3Plus(image_size, num_classes, name):\n",
    "    # Define model input\n",
    "    model_input = layers.Input(shape=(image_size, image_size, 3))\n",
    "    deeplab_model = DeepLabV3Plus(image_size=image_size, num_classes=num_classes)\n",
    "    model_output = deeplab_model(model_input)\n",
    "    model = models.Model(inputs=model_input, outputs=model_output, name=name)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "model = build_DeepLabV3Plus(image_size=patch_size[0], num_classes=1, name=\"DeepLabV3p\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653b6197-5485-4251-a9c9-2b5ddbba19cb",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52013c6-d215-4373-97f2-396e1c89c4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.Adam(), \n",
    "              loss=iou_loss,\n",
    "              metrics=[\n",
    "                  # metrics.BinaryAccuracy(),\n",
    "                  metrics.MeanIoU(num_classes=2),\n",
    "                  metrics.BinaryIoU(target_class_ids=[1]),\n",
    "                  metrics.IoU(num_classes=2, target_class_ids=[1]),\n",
    "                  metrics.Accuracy(),\n",
    "                  metrics.Precision(),\n",
    "                  metrics.Recall(),\n",
    "                  # metrics.F1Score(average=\"micro\", name=\"f1_micro\",  num_classes=2),\n",
    "                  # metrics.F1Score(average=\"macro\", name=\"f1_macro\", num_classes=2)\n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8194535e-0910-4cc1-b7d2-f62a2229afd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=model_name,\n",
    "    save_weights_only=False,  # Set to True to save only weights, False to save the whole model\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True,\n",
    "    verbose=1)  # Log a message whenever the model is saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf551df-27eb-48ec-83ef-1195ea5d0e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02685a3-2d29-4385-b0f8-2ca6c6d0f763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, fit the model using these datasets\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%m-%d_%H:%M\") + f\"_{model_name.split('.keras')[0]}\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=10,\n",
    "    validation_data=test_dataset,\n",
    "    callbacks=[model_checkpoint_callback, tensorboard_callback],\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ae8d3e-6f98-4a30-be87-7e6ad521be8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718600d8-476b-427a-ad4a-95f63f552a24",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8702f13d-1f49-4ec4-8114-ed066e513e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Now, include this callback in your model.fit() call\n",
    "# history = model.fit(\n",
    "#     X_train, y_train,\n",
    "#     epochs=10,\n",
    "#     batch_size=64,\n",
    "#     validation_split=0.25, # Should be a individual fold\n",
    "#     callbacks=[model_checkpoint_callback],  # Include the callback here\n",
    "#     verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1d39a7-5e3c-4ab9-92d8-0a325d558ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the history of training and validation loss\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Extracting the history of training and validation accuracy\n",
    "# Note: Replace 'accuracy' with 'acc' if your Keras version uses 'acc' instead\n",
    "accuracy = history.history['binary_accuracy']\n",
    "val_accuracy = history.history['val_binary_accuracy']\n",
    "\n",
    "binary_io_u = history.history['binary_io_u']\n",
    "val_binary_io_u = history.history['val_binary_io_u']\n",
    "\n",
    "# Setting up the subplot for loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(loss, label='Train BinaryFocalCrossentropy')\n",
    "plt.plot(val_loss, label='Val BinaryFocalCrossentropy')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Setting up the subplot for accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "# plt.plot(accuracy, label='Train Acc')\n",
    "# plt.plot(val_accuracy, label='Val Acc')\n",
    "\n",
    "plt.plot(binary_io_u, label='Train Binary IoU Acc')\n",
    "plt.plot(val_binary_io_u, label='Val Binary IoU Acc')\n",
    "\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb68089-7425-4702-9e19-1eb6b23f15c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model from the file\n",
    "model = load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a048ea98-5b89-4f48-8f31-3c4ffcbd5762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to visualize dataset samples\n",
    "def visualize_sample(image, mask, prediction):\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "\n",
    "    ax[0].imshow(image.numpy(), cmap='gray')\n",
    "    ax[0].set_title('Image')\n",
    "    \n",
    "    ax[1].imshow(mask.numpy(), cmap='gray')\n",
    "    ax[1].set_title('Mask')\n",
    "    \n",
    "    ax[2].imshow(prediction, cmap='gray')\n",
    "    ax[2].set_title('Prediction')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# # Visualize samples\n",
    "# for i, (image, mask) in enumerate(test_dataset.unbatch().take(3)):\n",
    "#     visualize_sample(image, mask, y_pred[i])\n",
    "\n",
    "# Randomly select 10 samples from the dataset\n",
    "test_dataset_array = test_dataset.unbatch().take(100)\n",
    "\n",
    "# Predict masks for the selected samples\n",
    "test_pred = model.predict(test_dataset_array.batch(1))  # Ensure batch size is 1 for individual predictions\n",
    "\n",
    "# Visualize samples along with their predictions\n",
    "for (image, mask), pred in zip(test_dataset_array, test_pred):\n",
    "    visualize_sample(image, mask, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c534e64-ded2-476e-8bf3-872d4a77a050",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c70dcf7-5a03-4a31-942d-41ec3e1b3418",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "\n",
    "id_ = random.randint(0, y_pred.shape[0])\n",
    "\n",
    "ax[0].imshow(X_test[id_], cmap='gray')\n",
    "ax[0].set_title('Image')\n",
    "ax[1].imshow(y_test[id_], cmap='gray')\n",
    "ax[1].set_title('Mask')\n",
    "ax[2].imshow(y_pred[id_], cmap='gray')\n",
    "ax[2].set_title('Pred')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb54e61-955f-4b0f-bd59-be602ef47481",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
