{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b60cacd",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43e2c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import geopandas as gpd\n",
    "from rasterio.features import rasterize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35887d9-9454-44f2-82b4-bb0ba7dc4b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, MaxPooling2D, Dropout, Conv2DTranspose, concatenate\n",
    "from tensorflow.keras import layers, models, optimizers, losses, metrics\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1f2ad9-7810-4a91-b107-b46fc474650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_rasterize_image(tif_path, shape_file_path):\n",
    "    with rasterio.open(tif_path) as src:\n",
    "        image = src.read([1, 2, 3])  # Reading the first three bands (assuming RGB)\n",
    "        transform = src.transform\n",
    "\n",
    "    # Read the shapefile\n",
    "    shapes = gpd.read_file(shape_file_path)\n",
    "\n",
    "    # Rasterize the shapefile to create a mask\n",
    "    mask = rasterize(\n",
    "        [(shape, 1) for shape in shapes.geometry],\n",
    "        out_shape=image[0].shape,\n",
    "        transform=transform,\n",
    "        fill=0,\n",
    "        all_touched=True,\n",
    "        dtype='uint8'\n",
    "    )\n",
    "    \n",
    "\n",
    "    # Normalize the image\n",
    "    image = image / 255.0\n",
    "    return image.transpose((1, 2, 0)), mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c330de2-6526-43e2-a67f-181d2d55c632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_into_patches(image, mask, patch_size):\n",
    "    \"\"\"\n",
    "    Divides an image and its mask into smaller patches.\n",
    "\n",
    "    Parameters:\n",
    "    - image: The image to be divided (numpy array).\n",
    "    - mask: The corresponding mask for the image (numpy array).\n",
    "    - patch_size: The size of each patch (tuple of two integers).\n",
    "\n",
    "    Returns:\n",
    "    - image_patches: A list of image patches.\n",
    "    - mask_patches: A list of mask patches.\n",
    "    \"\"\"\n",
    "    # Ensure the input dimensions are compatible\n",
    "    assert image.shape[0:2] == mask.shape[0:2], \"Image and mask must have the same dimensions\"\n",
    "    \n",
    "    # Calculate the number of patches along each dimension\n",
    "    patches_along_height = image.shape[0] // patch_size[0]\n",
    "    patches_along_width = image.shape[1] // patch_size[1]\n",
    "\n",
    "    image_patches = []\n",
    "    mask_patches = []\n",
    "\n",
    "    for i in range(patches_along_height):\n",
    "        for j in range(patches_along_width):\n",
    "            # Calculate patch coordinates\n",
    "            start_row = i * patch_size[0]\n",
    "            end_row = start_row + patch_size[0]\n",
    "            start_col = j * patch_size[1]\n",
    "            end_col = start_col + patch_size[1]\n",
    "\n",
    "            # Extract patches\n",
    "            image_patch = image[start_row:end_row, start_col:end_col]\n",
    "            mask_patch = mask[start_row:end_row, start_col:end_col]\n",
    "\n",
    "            image_patches.append(image_patch)\n",
    "            mask_patches.append(mask_patch)\n",
    "\n",
    "    return np.array(image_patches), np.array(mask_patches)\n",
    "\n",
    "def reshape_into_patched(image, mask, patch_size):\n",
    "    patch_size = list(patch_size)\n",
    "    mosaic_size = tuple(patch_size.insert(0, -1))\n",
    "    return image.reshape(mosaic_size), mask_patches.reshape(mosaic_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5692a950-35c5-4bad-bbfc-63795c447245",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = [\"2022_131000_456000_RGB_hrl\", \"2022_133000_456000_RGB_hrl\", \"2022_136000_457000_RGB_hrl\", \"2022_129000_458000_RGB_hrl\", \"2022_131000_455000_RGB_hrl\"]\n",
    "patch_size = (512, 512)\n",
    "\n",
    "def pre_process(file_names):\n",
    "    folds = {}\n",
    "    for i, file_name in enumerate(file_names):\n",
    "        mask_path = f\"masks/{file_name}.gpkg\"\n",
    "        tif_path = f\"nl_8cm/{file_name}.tif\"\n",
    "        image, mask = read_and_rasterize_image(tif_path, mask_path)\n",
    "        image, mask = divide_into_patches(image=image, mask=mask, patch_size=(512, 512))\n",
    "        # image, mask = reshape_into_patched(image=image, mask=mask, patch_size=(500, 500))\n",
    "        folds[i] = {\"images\": image, \"masks\": mask}\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156ee80d-ddd8-40c6-98bf-15b401b9bb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images_masks(folds, n_images = 10):\n",
    "    fold = 0\n",
    "    \n",
    "    num_images = len(folds[fold]['images'])\n",
    "    indices = np.random.choice(range(num_images), size=n_images, replace=False)\n",
    "    \n",
    "    # Set up the matplotlib figure and axes\n",
    "    fig, axs = plt.subplots(10, 2, figsize=(10, 40))  # Adjust figsize as needed\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        image = folds[fold][\"images\"][idx] # Load the image\n",
    "        mask = folds[fold][\"masks\"][idx]  # Load the corresponding mask\n",
    "    \n",
    "        axs[i, 0].imshow(image, cmap='gray')\n",
    "        axs[i, 0].axis('off')  # Remove axis ticks and labels\n",
    "        axs[i, 0].set_title(f\"Image {idx}\")\n",
    "    \n",
    "        axs[i, 1].imshow(mask, cmap='gray')\n",
    "        axs[i, 1].axis('off')\n",
    "        axs[i, 1].set_title(f\"Mask {idx}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc41a7d-f2bf-4b26-aa1d-25efaea20a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sets_from_folds(folds):\n",
    "    train_folds = [0, 1, 2, 3]\n",
    "    test_fold = 4\n",
    "    \n",
    "    X_train = np.concatenate([folds[i]['images'] for i in train_folds], axis=0)\n",
    "    y_train = np.concatenate([folds[i]['masks'] for i in train_folds], axis=0)\n",
    "    X_test, y_test = folds[test_fold]['images'], folds[test_fold]['masks']\n",
    "    return (X_train, y_train), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef95fb0b-e56e-499f-ab58-572fcb6ddc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=16\n",
    "train_dataset_save_path = 'train_dataset'\n",
    "test_dataset_save_path = 'test_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b77c680-8060-426c-a167-7c98616db325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment for preprocessing\n",
    "# folds = pre_process(file_names)\n",
    "# print(\"Loaded all images & mosaiced them.\")\n",
    "\n",
    "# # show_images_masks(folds)\n",
    "\n",
    "# (X_train, y_train), (X_test, y_test) = create_sets_from_folds(folds)\n",
    "# print(\"Created folds and put them together as a train & test sets.\")\n",
    "# print(\n",
    "#     X_train.shape,\n",
    "#     y_train.shape,\n",
    "#     X_test.shape\n",
    "# )\n",
    "\n",
    "# # Convert data to tf.data.Dataset and cast to float32\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices((X_train.astype(np.float32), y_train.astype(np.uint8)))\n",
    "# test_dataset = tf.data.Dataset.from_tensor_slices((X_test.astype(np.float32), y_test.astype(np.uint8)))\n",
    "# print(\"Converted sets to tf.Datasets and casted to float32.\")\n",
    "\n",
    "# # Shuffle, batch, and prefetch the training dataset\n",
    "# train_dataset = train_dataset.shuffle(buffer_size=len(X_train)).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# # Batch and prefetch the test dataset\n",
    "# test_dataset = test_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "# print(\"Buffered & batched sets.\")\n",
    "\n",
    "# # Save training dataset\n",
    "# train_dataset_save_path = 'train_dataset'\n",
    "# tf.data.Dataset.save(train_dataset, train_dataset_save_path) # options=compression_opts\n",
    "# print(\"Saved Train set.\")\n",
    "\n",
    "# # Save test dataset\n",
    "# test_dataset_save_path = 'test_dataset'\n",
    "# tf.data.Dataset.save(test_dataset, test_dataset_save_path) # options=compression_opts\n",
    "# print(\"Saved Test set.\")\n",
    "\n",
    "\n",
    "# del folds\n",
    "# del X_train\n",
    "# del y_train\n",
    "# del X_test\n",
    "# del y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0891e188-b78d-4948-b37b-f7c695b5cb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training dataset\n",
    "train_dataset = tf.data.Dataset.load(train_dataset_save_path, \n",
    "                                           element_spec=(tf.TensorSpec(shape=(patch_size[0], patch_size[1], 3), dtype=tf.float32),\n",
    "                                                         tf.TensorSpec(shape=(patch_size[0], patch_size[1]), dtype=tf.uint8)))\n",
    "\n",
    "# Load test dataset\n",
    "test_dataset = tf.data.Dataset.load(test_dataset_save_path, \n",
    "                                          element_spec=(tf.TensorSpec(shape=(patch_size[0], patch_size[1], 3), dtype=tf.float32),\n",
    "                                                        tf.TensorSpec(shape=(patch_size[0], patch_size[1]), dtype=tf.uint8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64191818-085c-4e64-afc4-769d8590118c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.batch(batch_size)\n",
    "test_dataset = test_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6eacd2-1f15-4ebc-82fd-c776c174a6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.element_spec, test_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12c4f5e-0512-4369-81e7-ce765cb94738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_loss(y_true, y_pred):\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection\n",
    "    iou_score = intersection / (union + tf.keras.backend.epsilon())  # Add epsilon to avoid division by zero\n",
    "    return 1.0 - iou_score  # Minimize 1 - IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8895fed2-c7bc-408b-bd4c-78616d059c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(inputs, num_filters):\n",
    "    x = layers.Conv2D(num_filters, 3, padding=\"same\")(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = tf.keras.activations.relu(x)\n",
    "    x = layers.Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = tf.keras.activations.relu(x)\n",
    "    return x\n",
    "\n",
    "def downsample_block(inputs, num_filters):\n",
    "    x = conv_block(inputs, num_filters)\n",
    "    p = layers.MaxPooling2D((2, 2))(x)\n",
    "    return x, p\n",
    "\n",
    "def upsample_block(inputs, skip_features, num_filters):\n",
    "    x = layers.Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(inputs)\n",
    "    x = layers.Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "def build_unet(input_shape):\n",
    "    inputs = layers.Input(input_shape)\n",
    "\n",
    "    s1, p1 = downsample_block(inputs, 64) # 512 -> 256\n",
    "    s2, p2 = downsample_block(p1, 128) # 256 -> 128\n",
    "    s3, p3 = downsample_block(p2, 256) # 128 -> 64\n",
    "\n",
    "    b = conv_block(p3, 256)\n",
    "\n",
    "    d1 = upsample_block(b, s3, 256) # 64 -> 128\n",
    "    d2 = upsample_block(d1, s2, 128) # 128 -> 256\n",
    "    d3 = upsample_block(d2, s1, 64) # 256 -> 512\n",
    "\n",
    "    outputs = layers.Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(d3)\n",
    "\n",
    "    model = models.Model(inputs, outputs, name=\"U-Net\")\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_unet(input_shape=(patch_size[0], patch_size[1], 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52013c6-d215-4373-97f2-396e1c89c4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.Adam(), \n",
    "              loss=iou_loss,\n",
    "              metrics=[metrics.BinaryAccuracy(), metrics.IoU(num_classes=2, target_class_ids=[1])])\n",
    "# Loss vervang met iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8194535e-0910-4cc1-b7d2-f62a2229afd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=\"model.keras\",\n",
    "    save_weights_only=False,  # Set to True to save only weights, False to save the whole model\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True,\n",
    "    verbose=1)  # Log a message whenever the model is saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02685a3-2d29-4385-b0f8-2ca6c6d0f763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, fit the model using these datasets\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=10,\n",
    "    validation_data=test_dataset,\n",
    "    callbacks=[model_checkpoint_callback],\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ae8d3e-6f98-4a30-be87-7e6ad521be8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8702f13d-1f49-4ec4-8114-ed066e513e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Now, include this callback in your model.fit() call\n",
    "# history = model.fit(\n",
    "#     X_train, y_train,\n",
    "#     epochs=10,\n",
    "#     batch_size=64,\n",
    "#     validation_split=0.25, # Should be a individual fold\n",
    "#     callbacks=[model_checkpoint_callback],  # Include the callback here\n",
    "#     verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1d39a7-5e3c-4ab9-92d8-0a325d558ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the history of training and validation loss\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Extracting the history of training and validation accuracy\n",
    "# Note: Replace 'accuracy' with 'acc' if your Keras version uses 'acc' instead\n",
    "accuracy = history.history['binary_accuracy']\n",
    "val_accuracy = history.history['val_binary_accuracy']\n",
    "\n",
    "# Setting up the subplot for loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Setting up the subplot for accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(accuracy, label='Training Accuracy')\n",
    "plt.plot(val_accuracy, label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb68089-7425-4702-9e19-1eb6b23f15c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model from the file\n",
    "model = load_model('model.keras', custom_objects={'iou_loss': iou_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2012cd35-ad72-4349-871f-9eb9d4e53781",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a048ea98-5b89-4f48-8f31-3c4ffcbd5762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to visualize dataset samples\n",
    "def visualize_sample(image, mask, prediction):\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "\n",
    "    ax[0].imshow(image.numpy(), cmap='gray')\n",
    "    ax[0].set_title('Image')\n",
    "    \n",
    "    ax[1].imshow(mask.numpy(), cmap='gray')\n",
    "    ax[1].set_title('Mask')\n",
    "    \n",
    "    ax[2].imshow(prediction, cmap='gray')\n",
    "    ax[2].set_title('Prediction')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# # Visualize samples\n",
    "# for i, (image, mask) in enumerate(test_dataset.unbatch().take(3)):\n",
    "#     visualize_sample(image, mask, y_pred[i])\n",
    "\n",
    "# Randomly select 10 samples from the dataset\n",
    "test_dataset_array = test_dataset.unbatch().take(10)\n",
    "\n",
    "# Predict masks for the selected samples\n",
    "test_pred = model.predict(test_dataset_array.batch(1))  # Ensure batch size is 1 for individual predictions\n",
    "\n",
    "# Visualize samples along with their predictions\n",
    "for (image, mask), pred in zip(test_dataset_array, test_pred):\n",
    "    visualize_sample(image, mask, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c534e64-ded2-476e-8bf3-872d4a77a050",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c70dcf7-5a03-4a31-942d-41ec3e1b3418",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "\n",
    "id_ = random.randint(0, y_pred.shape[0])\n",
    "\n",
    "ax[0].imshow(X_test[id_], cmap='gray')\n",
    "ax[0].set_title('Image')\n",
    "ax[1].imshow(y_test[id_], cmap='gray')\n",
    "ax[1].set_title('Mask')\n",
    "ax[2].imshow(y_pred[id_], cmap='gray')\n",
    "ax[2].set_title('Pred')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb54e61-955f-4b0f-bd59-be602ef47481",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
